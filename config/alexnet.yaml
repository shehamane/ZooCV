input:
  w: 224
  h: 224
  ch: 3
activation: ReLU
backbone: [
  [ -1, 1, ConvBN, [ 96, 11, 4 ] ],
  [ -1, 1, MaxPool, [ 3, 2 ] ],
  [ -1, 1, ConvBN, [ 256, 5, 1, 2 ] ],
  [ -1, 1, MaxPool, [ 3, 2 ] ],
  [ -1, 1, Conv, [ 384, 3, 1, 1 ] ],
  [ -1, 1, Conv, [ 384, 3, 1, 1 ] ],
  [ -1, 1, Conv, [ 256, 3, 1, 1 ] ],
  [ -1, 1, MaxPool, [ 3, 2 ] ],

  [ -1, 1, FC, [ 512 ] ],
  [ -1, 1, Dropout, 0.5 ],
  [ -1, 1, FC, [ 128 ] ],
  [ -1, 1, Dropout, 0.5 ],
  [ -1, 1, FC, [ 10 ] ],
  [ -1, 1, Softmax ]
]
