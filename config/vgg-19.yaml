input:
  w: 224
  h: 224
  ch: 3
activation: ReLU
backbone: [
  [ -1, 1, Conv, [ 64, 3, 1, 1 ] ],
  [ -1, 1, Conv, [ 64, 3, 1, 1 ] ],
  [ -1, 1, MaxPool, [ 2, 2 ] ],

  [ -1, 1, Conv, [ 128, 3, 1, 1 ] ],
  [ -1, 1, Conv, [ 128, 3, 1, 1 ] ],
  [ -1, 1, MaxPool, [ 2, 2 ] ],

  [ -1, 1, Conv, [ 256, 3, 1, 1 ] ],
  [ -1, 1, Conv, [ 256, 3, 1, 1 ] ],
  [ -1, 1, Conv, [ 256, 3, 1, 1 ] ],
  [ -1, 1, Conv, [ 256, 3, 1, 1 ] ],
  [ -1, 1, MaxPool, [ 2, 2 ] ],

  [ -1, 1, Conv, [ 512, 3, 1, 1 ] ],
  [ -1, 1, Conv, [ 512, 3, 1, 1 ] ],
  [ -1, 1, Conv, [ 512, 3, 1, 1 ] ],
  [ -1, 1, Conv, [ 512, 3, 1, 1 ] ],
  [ -1, 1, MaxPool, [ 2, 2 ] ],

  [ -1, 1, Conv, [ 512, 3, 1, 1 ] ],
  [ -1, 1, Conv, [ 512, 3, 1, 1 ] ],
  [ -1, 1, Conv, [ 512, 3, 1, 1 ] ],
  [ -1, 1, Conv, [ 512, 3, 1, 1 ] ],
  [ -1, 1, MaxPool, [ 2, 2 ] ],

  [-1, 1, FC, [4096]],
  [-1, 1, Dropout, 0.5],
  [-1, 1, FC, [4096]],
  [ -1, 1, Dropout, 0.5 ],
  [-1, 1, FC, [$nc]],
  [-1, 1, Softmax]
]