{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T14:08:35.322409Z",
     "start_time": "2024-08-21T14:08:34.884526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "ff9840ba88218221",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Подготовка",
   "id": "2ae34e32e760cb40"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Датасет\n",
    "Для тестирования LeNet-5 можно использовать датасет FashionMNIT, так как изображения в нем размера $28 \\times 28$, как раз подходит под вход без ресайза"
   ],
   "id": "5659fc629efcfe93"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T14:08:44.064908Z",
     "start_time": "2024-08-21T14:08:43.680615Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from data.mnist import MNIST\n",
    "\n",
    "\n",
    "train_data = MNIST(\n",
    "    root='../dataset/MNIST/',\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = MNIST(\n",
    "    root='../dataset/MNIST/',\n",
    "    train=False,\n",
    "    transform=transforms.ToTensor(),\n",
    ")"
   ],
   "id": "b003c7fd-9407-4b39-a8ec-1c9c0e3dac0f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T14:08:57.382514Z",
     "start_time": "2024-08-21T14:08:57.087124Z"
    }
   },
   "cell_type": "code",
   "source": "plt.imshow(train_data[0][1].permute((1, 2, 0)))",
   "id": "f696753af592e7ef",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f10588976d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Проверка использования GPU",
   "id": "e5bf716a49352d07"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T14:08:58.394908Z",
     "start_time": "2024-08-21T14:08:58.347879Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.is_available()",
   "id": "fc03513a27c415e7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T14:08:58.835111Z",
     "start_time": "2024-08-21T14:08:58.790873Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.current_device()",
   "id": "5c0517ce9ca11a0f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T14:08:59.175779Z",
     "start_time": "2024-08-21T14:08:59.148661Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.get_device_name()",
   "id": "54394d3372ec86d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1070 Ti'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Подготовка модели и лоадеров",
   "id": "2ad38bcd21452d3a"
  },
  {
   "cell_type": "code",
   "id": "d794d1cf-53e2-444f-84a2-97778ef56009",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T14:55:01.252621Z",
     "start_time": "2024-08-21T14:55:01.215602Z"
    }
   },
   "source": [
    "batch_size = 64\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)"
   ],
   "outputs": [],
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "id": "8bc55a57-ea68-40dc-bc8e-4f8d749027e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T14:56:23.723330Z",
     "start_time": "2024-08-21T14:56:22.114310Z"
    }
   },
   "source": [
    "from model.lenet5 import LeNet5\n",
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from evaluation.eval import ClassificationEvaluator\n",
    "from evaluation.metrics import Metric\n",
    "from evaluation.logging import NotebookLogger\n",
    "\n",
    "model = LeNet5('../config/lenet-5.yaml', nc=10)\n",
    "optimizer = SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "loss_fn = CrossEntropyLoss()\n",
    "evaluator = ClassificationEvaluator([Metric.Accuracy, Metric.Precision, Metric.Recall, Metric.F1], logger=NotebookLogger)"
   ],
   "outputs": [],
   "execution_count": 92
  },
  {
   "cell_type": "code",
   "id": "9a01a604-6dda-4fa0-87b0-28a85e682f07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T14:56:23.750196Z",
     "start_time": "2024-08-21T14:56:23.725443Z"
    }
   },
   "source": [
    "from trainer.supervised import ClassificationTrainer\n",
    "\n",
    "trainer = ClassificationTrainer(model, train_loader, test_loader, loss_fn, optimizer, evaluator, eval_freq=100)"
   ],
   "outputs": [],
   "execution_count": 93
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Тестирование",
   "id": "804ed474f234296f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T14:56:42.414950Z",
     "start_time": "2024-08-21T14:56:23.751056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    trainer.train()"
   ],
   "id": "c7a8e84e2ee7f075",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.036150217056274414\n",
      "Current metrics:\n",
      "    Accuracy  Precision  Recall      F1     loss\n",
      "id                                              \n",
      "0     0.1032     0.1032  0.1032  0.1032  0.03615\n",
      "Validation loss: 0.0360942967236042\n",
      "Current metrics:\n",
      "     Accuracy  Precision  Recall      F1      loss\n",
      "id                                                \n",
      "0      0.1032     0.1032  0.1032  0.1032  0.036150\n",
      "100    0.2830     0.2830  0.2830  0.2830  0.036094\n",
      "Validation loss: 0.03030289150774479\n",
      "Current metrics:\n",
      "     Accuracy  Precision  Recall      F1      loss\n",
      "id                                                \n",
      "0      0.1032     0.1032  0.1032  0.1032  0.036150\n",
      "100    0.2830     0.2830  0.2830  0.2830  0.036094\n",
      "200    0.5273     0.5273  0.5273  0.5273  0.030303\n",
      "Validation loss: 0.02961406111717224\n",
      "Current metrics:\n",
      "     Accuracy  Precision  Recall      F1      loss\n",
      "id                                                \n",
      "0      0.1032     0.1032  0.1032  0.1032  0.036150\n",
      "100    0.2830     0.2830  0.2830  0.2830  0.036094\n",
      "200    0.5273     0.5273  0.5273  0.5273  0.030303\n",
      "300    0.5687     0.5687  0.5687  0.5687  0.029614\n",
      "Validation loss: 0.027585133910179138\n",
      "Current metrics:\n",
      "     Accuracy  Precision  Recall      F1      loss\n",
      "id                                                \n",
      "0      0.1032     0.1032  0.1032  0.1032  0.036150\n",
      "100    0.2830     0.2830  0.2830  0.2830  0.036094\n",
      "200    0.5273     0.5273  0.5273  0.5273  0.030303\n",
      "300    0.5687     0.5687  0.5687  0.5687  0.029614\n",
      "400    0.7060     0.7060  0.7060  0.7060  0.027585\n",
      "Validation loss: 0.026856636628508568\n",
      "Current metrics:\n",
      "     Accuracy  Precision  Recall      F1      loss\n",
      "id                                                \n",
      "0      0.1032     0.1032  0.1032  0.1032  0.036150\n",
      "100    0.2830     0.2830  0.2830  0.2830  0.036094\n",
      "200    0.5273     0.5273  0.5273  0.5273  0.030303\n",
      "300    0.5687     0.5687  0.5687  0.5687  0.029614\n",
      "400    0.7060     0.7060  0.7060  0.7060  0.027585\n",
      "500    0.7497     0.7497  0.7497  0.7497  0.026857\n",
      "Validation loss: 0.027040163055062294\n",
      "Current metrics:\n",
      "     Accuracy  Precision  Recall      F1      loss\n",
      "id                                                \n",
      "0      0.1032     0.1032  0.1032  0.1032  0.036150\n",
      "100    0.2830     0.2830  0.2830  0.2830  0.036094\n",
      "200    0.5273     0.5273  0.5273  0.5273  0.030303\n",
      "300    0.5687     0.5687  0.5687  0.5687  0.029614\n",
      "400    0.7060     0.7060  0.7060  0.7060  0.027585\n",
      "500    0.7497     0.7497  0.7497  0.7497  0.026857\n",
      "600    0.7374     0.7374  0.7374  0.7374  0.027040\n",
      "Validation loss: 0.02658127434551716\n",
      "Current metrics:\n",
      "     Accuracy  Precision  Recall      F1      loss\n",
      "id                                                \n",
      "0      0.1032     0.1032  0.1032  0.1032  0.036150\n",
      "100    0.2830     0.2830  0.2830  0.2830  0.036094\n",
      "200    0.5273     0.5273  0.5273  0.5273  0.030303\n",
      "300    0.5687     0.5687  0.5687  0.5687  0.029614\n",
      "400    0.7060     0.7060  0.7060  0.7060  0.027585\n",
      "500    0.7497     0.7497  0.7497  0.7497  0.026857\n",
      "600    0.7374     0.7374  0.7374  0.7374  0.027040\n",
      "700    0.7674     0.7674  0.7674  0.7674  0.026581\n",
      "Validation loss: 0.026908105239272118\n",
      "Current metrics:\n",
      "     Accuracy  Precision  Recall      F1      loss\n",
      "id                                                \n",
      "0      0.1032     0.1032  0.1032  0.1032  0.036150\n",
      "100    0.2830     0.2830  0.2830  0.2830  0.036094\n",
      "200    0.5273     0.5273  0.5273  0.5273  0.030303\n",
      "300    0.5687     0.5687  0.5687  0.5687  0.029614\n",
      "400    0.7060     0.7060  0.7060  0.7060  0.027585\n",
      "500    0.7497     0.7497  0.7497  0.7497  0.026857\n",
      "600    0.7374     0.7374  0.7374  0.7374  0.027040\n",
      "700    0.7674     0.7674  0.7674  0.7674  0.026581\n",
      "800    0.7457     0.7457  0.7457  0.7457  0.026908\n",
      "Validation loss: 0.02639426477253437\n",
      "Current metrics:\n",
      "     Accuracy  Precision  Recall      F1      loss\n",
      "id                                                \n",
      "0      0.1032     0.1032  0.1032  0.1032  0.036150\n",
      "100    0.2830     0.2830  0.2830  0.2830  0.036094\n",
      "200    0.5273     0.5273  0.5273  0.5273  0.030303\n",
      "300    0.5687     0.5687  0.5687  0.5687  0.029614\n",
      "400    0.7060     0.7060  0.7060  0.7060  0.027585\n",
      "500    0.7497     0.7497  0.7497  0.7497  0.026857\n",
      "600    0.7374     0.7374  0.7374  0.7374  0.027040\n",
      "700    0.7674     0.7674  0.7674  0.7674  0.026581\n",
      "800    0.7457     0.7457  0.7457  0.7457  0.026908\n",
      "900    0.7789     0.7789  0.7789  0.7789  0.026394\n",
      "Loss for id 937: 0.02887121405005455\n",
      "Validation loss: 0.026422740891575813\n",
      "Current metrics:\n",
      "      Accuracy  Precision  Recall      F1      loss\n",
      "id                                                 \n",
      "0       0.1032     0.1032  0.1032  0.1032  0.036150\n",
      "100     0.2830     0.2830  0.2830  0.2830  0.036094\n",
      "200     0.5273     0.5273  0.5273  0.5273  0.030303\n",
      "300     0.5687     0.5687  0.5687  0.5687  0.029614\n",
      "400     0.7060     0.7060  0.7060  0.7060  0.027585\n",
      "500     0.7497     0.7497  0.7497  0.7497  0.026857\n",
      "600     0.7374     0.7374  0.7374  0.7374  0.027040\n",
      "700     0.7674     0.7674  0.7674  0.7674  0.026581\n",
      "800     0.7457     0.7457  0.7457  0.7457  0.026908\n",
      "900     0.7789     0.7789  0.7789  0.7789  0.026394\n",
      "1000    0.7767     0.7767  0.7767  0.7767  0.026423\n",
      "Validation loss: 0.02645762823522091\n",
      "Current metrics:\n",
      "      Accuracy  Precision  Recall      F1      loss\n",
      "id                                                 \n",
      "0       0.1032     0.1032  0.1032  0.1032  0.036150\n",
      "100     0.2830     0.2830  0.2830  0.2830  0.036094\n",
      "200     0.5273     0.5273  0.5273  0.5273  0.030303\n",
      "300     0.5687     0.5687  0.5687  0.5687  0.029614\n",
      "400     0.7060     0.7060  0.7060  0.7060  0.027585\n",
      "500     0.7497     0.7497  0.7497  0.7497  0.026857\n",
      "600     0.7374     0.7374  0.7374  0.7374  0.027040\n",
      "700     0.7674     0.7674  0.7674  0.7674  0.026581\n",
      "800     0.7457     0.7457  0.7457  0.7457  0.026908\n",
      "900     0.7789     0.7789  0.7789  0.7789  0.026394\n",
      "1000    0.7767     0.7767  0.7767  0.7767  0.026423\n",
      "1100    0.7751     0.7751  0.7751  0.7751  0.026458\n",
      "Validation loss: 0.026374539360404015\n",
      "Current metrics:\n",
      "      Accuracy  Precision  Recall      F1      loss\n",
      "id                                                 \n",
      "0       0.1032     0.1032  0.1032  0.1032  0.036150\n",
      "100     0.2830     0.2830  0.2830  0.2830  0.036094\n",
      "200     0.5273     0.5273  0.5273  0.5273  0.030303\n",
      "300     0.5687     0.5687  0.5687  0.5687  0.029614\n",
      "400     0.7060     0.7060  0.7060  0.7060  0.027585\n",
      "500     0.7497     0.7497  0.7497  0.7497  0.026857\n",
      "600     0.7374     0.7374  0.7374  0.7374  0.027040\n",
      "700     0.7674     0.7674  0.7674  0.7674  0.026581\n",
      "800     0.7457     0.7457  0.7457  0.7457  0.026908\n",
      "900     0.7789     0.7789  0.7789  0.7789  0.026394\n",
      "1000    0.7767     0.7767  0.7767  0.7767  0.026423\n",
      "1100    0.7751     0.7751  0.7751  0.7751  0.026458\n",
      "1200    0.7798     0.7798  0.7798  0.7798  0.026375\n",
      "Validation loss: 0.026238515973091125\n",
      "Current metrics:\n",
      "      Accuracy  Precision  Recall      F1      loss\n",
      "id                                                 \n",
      "0       0.1032     0.1032  0.1032  0.1032  0.036150\n",
      "100     0.2830     0.2830  0.2830  0.2830  0.036094\n",
      "200     0.5273     0.5273  0.5273  0.5273  0.030303\n",
      "300     0.5687     0.5687  0.5687  0.5687  0.029614\n",
      "400     0.7060     0.7060  0.7060  0.7060  0.027585\n",
      "500     0.7497     0.7497  0.7497  0.7497  0.026857\n",
      "600     0.7374     0.7374  0.7374  0.7374  0.027040\n",
      "700     0.7674     0.7674  0.7674  0.7674  0.026581\n",
      "800     0.7457     0.7457  0.7457  0.7457  0.026908\n",
      "900     0.7789     0.7789  0.7789  0.7789  0.026394\n",
      "1000    0.7767     0.7767  0.7767  0.7767  0.026423\n",
      "1100    0.7751     0.7751  0.7751  0.7751  0.026458\n",
      "1200    0.7798     0.7798  0.7798  0.7798  0.026375\n",
      "1300    0.7868     0.7868  0.7868  0.7868  0.026239\n",
      "Validation loss: 0.024925878271460533\n",
      "Current metrics:\n",
      "      Accuracy  Precision  Recall      F1      loss\n",
      "id                                                 \n",
      "0       0.1032     0.1032  0.1032  0.1032  0.036150\n",
      "100     0.2830     0.2830  0.2830  0.2830  0.036094\n",
      "200     0.5273     0.5273  0.5273  0.5273  0.030303\n",
      "300     0.5687     0.5687  0.5687  0.5687  0.029614\n",
      "400     0.7060     0.7060  0.7060  0.7060  0.027585\n",
      "500     0.7497     0.7497  0.7497  0.7497  0.026857\n",
      "600     0.7374     0.7374  0.7374  0.7374  0.027040\n",
      "700     0.7674     0.7674  0.7674  0.7674  0.026581\n",
      "800     0.7457     0.7457  0.7457  0.7457  0.026908\n",
      "900     0.7789     0.7789  0.7789  0.7789  0.026394\n",
      "1000    0.7767     0.7767  0.7767  0.7767  0.026423\n",
      "1100    0.7751     0.7751  0.7751  0.7751  0.026458\n",
      "1200    0.7798     0.7798  0.7798  0.7798  0.026375\n",
      "1300    0.7868     0.7868  0.7868  0.7868  0.026239\n",
      "1400    0.8719     0.8719  0.8719  0.8719  0.024926\n",
      "Validation loss: 0.02409236878156662\n",
      "Current metrics:\n",
      "      Accuracy  Precision  Recall      F1      loss\n",
      "id                                                 \n",
      "0       0.1032     0.1032  0.1032  0.1032  0.036150\n",
      "100     0.2830     0.2830  0.2830  0.2830  0.036094\n",
      "200     0.5273     0.5273  0.5273  0.5273  0.030303\n",
      "300     0.5687     0.5687  0.5687  0.5687  0.029614\n",
      "400     0.7060     0.7060  0.7060  0.7060  0.027585\n",
      "500     0.7497     0.7497  0.7497  0.7497  0.026857\n",
      "600     0.7374     0.7374  0.7374  0.7374  0.027040\n",
      "700     0.7674     0.7674  0.7674  0.7674  0.026581\n",
      "800     0.7457     0.7457  0.7457  0.7457  0.026908\n",
      "900     0.7789     0.7789  0.7789  0.7789  0.026394\n",
      "1000    0.7767     0.7767  0.7767  0.7767  0.026423\n",
      "1100    0.7751     0.7751  0.7751  0.7751  0.026458\n",
      "1200    0.7798     0.7798  0.7798  0.7798  0.026375\n",
      "1300    0.7868     0.7868  0.7868  0.7868  0.026239\n",
      "1400    0.8719     0.8719  0.8719  0.8719  0.024926\n",
      "1500    0.9273     0.9273  0.9273  0.9273  0.024092\n",
      "Validation loss: 0.023803096264600754\n",
      "Current metrics:\n",
      "      Accuracy  Precision  Recall      F1      loss\n",
      "id                                                 \n",
      "0       0.1032     0.1032  0.1032  0.1032  0.036150\n",
      "100     0.2830     0.2830  0.2830  0.2830  0.036094\n",
      "200     0.5273     0.5273  0.5273  0.5273  0.030303\n",
      "300     0.5687     0.5687  0.5687  0.5687  0.029614\n",
      "400     0.7060     0.7060  0.7060  0.7060  0.027585\n",
      "500     0.7497     0.7497  0.7497  0.7497  0.026857\n",
      "600     0.7374     0.7374  0.7374  0.7374  0.027040\n",
      "700     0.7674     0.7674  0.7674  0.7674  0.026581\n",
      "800     0.7457     0.7457  0.7457  0.7457  0.026908\n",
      "900     0.7789     0.7789  0.7789  0.7789  0.026394\n",
      "1000    0.7767     0.7767  0.7767  0.7767  0.026423\n",
      "1100    0.7751     0.7751  0.7751  0.7751  0.026458\n",
      "1200    0.7798     0.7798  0.7798  0.7798  0.026375\n",
      "1300    0.7868     0.7868  0.7868  0.7868  0.026239\n",
      "1400    0.8719     0.8719  0.8719  0.8719  0.024926\n",
      "1500    0.9273     0.9273  0.9273  0.9273  0.024092\n",
      "1600    0.9459     0.9459  0.9459  0.9459  0.023803\n",
      "Validation loss: 0.02388354390859604\n",
      "Current metrics:\n",
      "      Accuracy  Precision  Recall      F1      loss\n",
      "id                                                 \n",
      "0       0.1032     0.1032  0.1032  0.1032  0.036150\n",
      "100     0.2830     0.2830  0.2830  0.2830  0.036094\n",
      "200     0.5273     0.5273  0.5273  0.5273  0.030303\n",
      "300     0.5687     0.5687  0.5687  0.5687  0.029614\n",
      "400     0.7060     0.7060  0.7060  0.7060  0.027585\n",
      "500     0.7497     0.7497  0.7497  0.7497  0.026857\n",
      "600     0.7374     0.7374  0.7374  0.7374  0.027040\n",
      "700     0.7674     0.7674  0.7674  0.7674  0.026581\n",
      "800     0.7457     0.7457  0.7457  0.7457  0.026908\n",
      "900     0.7789     0.7789  0.7789  0.7789  0.026394\n",
      "1000    0.7767     0.7767  0.7767  0.7767  0.026423\n",
      "1100    0.7751     0.7751  0.7751  0.7751  0.026458\n",
      "1200    0.7798     0.7798  0.7798  0.7798  0.026375\n",
      "1300    0.7868     0.7868  0.7868  0.7868  0.026239\n",
      "1400    0.8719     0.8719  0.8719  0.8719  0.024926\n",
      "1500    0.9273     0.9273  0.9273  0.9273  0.024092\n",
      "1600    0.9459     0.9459  0.9459  0.9459  0.023803\n",
      "1700    0.9407     0.9407  0.9407  0.9407  0.023884\n",
      "Validation loss: 0.023937147110700607\n",
      "Current metrics:\n",
      "      Accuracy  Precision  Recall      F1      loss\n",
      "id                                                 \n",
      "0       0.1032     0.1032  0.1032  0.1032  0.036150\n",
      "100     0.2830     0.2830  0.2830  0.2830  0.036094\n",
      "200     0.5273     0.5273  0.5273  0.5273  0.030303\n",
      "300     0.5687     0.5687  0.5687  0.5687  0.029614\n",
      "400     0.7060     0.7060  0.7060  0.7060  0.027585\n",
      "500     0.7497     0.7497  0.7497  0.7497  0.026857\n",
      "600     0.7374     0.7374  0.7374  0.7374  0.027040\n",
      "700     0.7674     0.7674  0.7674  0.7674  0.026581\n",
      "800     0.7457     0.7457  0.7457  0.7457  0.026908\n",
      "900     0.7789     0.7789  0.7789  0.7789  0.026394\n",
      "1000    0.7767     0.7767  0.7767  0.7767  0.026423\n",
      "1100    0.7751     0.7751  0.7751  0.7751  0.026458\n",
      "1200    0.7798     0.7798  0.7798  0.7798  0.026375\n",
      "1300    0.7868     0.7868  0.7868  0.7868  0.026239\n",
      "1400    0.8719     0.8719  0.8719  0.8719  0.024926\n",
      "1500    0.9273     0.9273  0.9273  0.9273  0.024092\n",
      "1600    0.9459     0.9459  0.9459  0.9459  0.023803\n",
      "1700    0.9407     0.9407  0.9407  0.9407  0.023884\n",
      "1800    0.9370     0.9370  0.9370  0.9370  0.023937\n",
      "Loss for id 1874: 0.025108542839686075\n",
      "Validation loss: 0.02367199771106243\n",
      "Current metrics:\n",
      "      Accuracy  Precision  Recall      F1      loss\n",
      "id                                                 \n",
      "0       0.1032     0.1032  0.1032  0.1032  0.036150\n",
      "100     0.2830     0.2830  0.2830  0.2830  0.036094\n",
      "200     0.5273     0.5273  0.5273  0.5273  0.030303\n",
      "300     0.5687     0.5687  0.5687  0.5687  0.029614\n",
      "400     0.7060     0.7060  0.7060  0.7060  0.027585\n",
      "500     0.7497     0.7497  0.7497  0.7497  0.026857\n",
      "600     0.7374     0.7374  0.7374  0.7374  0.027040\n",
      "700     0.7674     0.7674  0.7674  0.7674  0.026581\n",
      "800     0.7457     0.7457  0.7457  0.7457  0.026908\n",
      "900     0.7789     0.7789  0.7789  0.7789  0.026394\n",
      "1000    0.7767     0.7767  0.7767  0.7767  0.026423\n",
      "1100    0.7751     0.7751  0.7751  0.7751  0.026458\n",
      "1200    0.7798     0.7798  0.7798  0.7798  0.026375\n",
      "1300    0.7868     0.7868  0.7868  0.7868  0.026239\n",
      "1400    0.8719     0.8719  0.8719  0.8719  0.024926\n",
      "1500    0.9273     0.9273  0.9273  0.9273  0.024092\n",
      "1600    0.9459     0.9459  0.9459  0.9459  0.023803\n",
      "1700    0.9407     0.9407  0.9407  0.9407  0.023884\n",
      "1800    0.9370     0.9370  0.9370  0.9370  0.023937\n",
      "1900    0.9541     0.9541  0.9541  0.9541  0.023672\n",
      "Validation loss: 0.023931680247187614\n",
      "Current metrics:\n",
      "      Accuracy  Precision  Recall      F1      loss\n",
      "id                                                 \n",
      "0       0.1032     0.1032  0.1032  0.1032  0.036150\n",
      "100     0.2830     0.2830  0.2830  0.2830  0.036094\n",
      "200     0.5273     0.5273  0.5273  0.5273  0.030303\n",
      "300     0.5687     0.5687  0.5687  0.5687  0.029614\n",
      "400     0.7060     0.7060  0.7060  0.7060  0.027585\n",
      "500     0.7497     0.7497  0.7497  0.7497  0.026857\n",
      "600     0.7374     0.7374  0.7374  0.7374  0.027040\n",
      "700     0.7674     0.7674  0.7674  0.7674  0.026581\n",
      "800     0.7457     0.7457  0.7457  0.7457  0.026908\n",
      "900     0.7789     0.7789  0.7789  0.7789  0.026394\n",
      "1000    0.7767     0.7767  0.7767  0.7767  0.026423\n",
      "1100    0.7751     0.7751  0.7751  0.7751  0.026458\n",
      "1200    0.7798     0.7798  0.7798  0.7798  0.026375\n",
      "1300    0.7868     0.7868  0.7868  0.7868  0.026239\n",
      "1400    0.8719     0.8719  0.8719  0.8719  0.024926\n",
      "1500    0.9273     0.9273  0.9273  0.9273  0.024092\n",
      "1600    0.9459     0.9459  0.9459  0.9459  0.023803\n",
      "1700    0.9407     0.9407  0.9407  0.9407  0.023884\n",
      "1800    0.9370     0.9370  0.9370  0.9370  0.023937\n",
      "1900    0.9541     0.9541  0.9541  0.9541  0.023672\n",
      "2000    0.9361     0.9361  0.9361  0.9361  0.023932\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[94], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m100\u001B[39m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[0;32m----> 4\u001B[0m     trainer\u001B[38;5;241m.\u001B[39mtrain()\n",
      "File \u001B[0;32m~/Projects/ZooCV/trainer/supervised.py:43\u001B[0m, in \u001B[0;36mClassificationTrainer.train\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     40\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     42\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m it \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39meval_freq \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m---> 43\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluator\u001B[38;5;241m.\u001B[39mevaluate(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mval_loader, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_fn, it)\n\u001B[1;32m     44\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[1;32m     46\u001B[0m avg_loss \u001B[38;5;241m=\u001B[39m total_loss \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_loader\u001B[38;5;241m.\u001B[39mdataset)\n",
      "File \u001B[0;32m~/Projects/ZooCV/evaluation/eval.py:47\u001B[0m, in \u001B[0;36mClassificationEvaluator.evaluate\u001B[0;34m(self, model, loader, loss_fn, eval_id)\u001B[0m\n\u001B[1;32m     45\u001B[0m total_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m---> 47\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m it, (images, labels) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(loader):\n\u001B[1;32m     48\u001B[0m         images, labels \u001B[38;5;241m=\u001B[39m images\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice), labels\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m     49\u001B[0m         logits \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mnn(images)\n",
      "File \u001B[0;32m~/miniconda3/envs/zoocv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_data()\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/miniconda3/envs/zoocv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    674\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 675\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_fetcher\u001B[38;5;241m.\u001B[39mfetch(index)  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    676\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    677\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/miniconda3/envs/zoocv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[0;32m~/miniconda3/envs/zoocv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[0;32m~/Projects/ZooCV/data/base.py:62\u001B[0m, in \u001B[0;36mClassificationDataset.__getitem__\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m     60\u001B[0m im, label \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreceiver[idx]\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform:\n\u001B[0;32m---> 62\u001B[0m     im \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform(im)\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m idx, im, label\n",
      "File \u001B[0;32m~/miniconda3/envs/zoocv/lib/python3.11/site-packages/torchvision/transforms/transforms.py:137\u001B[0m, in \u001B[0;36mToTensor.__call__\u001B[0;34m(self, pic)\u001B[0m\n\u001B[1;32m    129\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, pic):\n\u001B[1;32m    130\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    131\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m    132\u001B[0m \u001B[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    135\u001B[0m \u001B[38;5;124;03m        Tensor: Converted image.\u001B[39;00m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 137\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mto_tensor(pic)\n",
      "File \u001B[0;32m~/miniconda3/envs/zoocv/lib/python3.11/site-packages/torchvision/transforms/functional.py:157\u001B[0m, in \u001B[0;36mto_tensor\u001B[0;34m(pic)\u001B[0m\n\u001B[1;32m    155\u001B[0m \u001B[38;5;66;03m# backward compatibility\u001B[39;00m\n\u001B[1;32m    156\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(img, torch\u001B[38;5;241m.\u001B[39mByteTensor):\n\u001B[0;32m--> 157\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img\u001B[38;5;241m.\u001B[39mto(dtype\u001B[38;5;241m=\u001B[39mdefault_float_dtype)\u001B[38;5;241m.\u001B[39mdiv(\u001B[38;5;241m255\u001B[39m)\n\u001B[1;32m    158\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    159\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T14:57:21.938106Z",
     "start_time": "2024-08-21T14:57:21.903224Z"
    }
   },
   "cell_type": "code",
   "source": "evaluator.logger.get_log()",
   "id": "10cce0d9d252328c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Accuracy  Precision  Recall      F1      loss\n",
       "id                                                 \n",
       "0       0.1032     0.1032  0.1032  0.1032  0.036150\n",
       "100     0.2830     0.2830  0.2830  0.2830  0.036094\n",
       "200     0.5273     0.5273  0.5273  0.5273  0.030303\n",
       "300     0.5687     0.5687  0.5687  0.5687  0.029614\n",
       "400     0.7060     0.7060  0.7060  0.7060  0.027585\n",
       "500     0.7497     0.7497  0.7497  0.7497  0.026857\n",
       "600     0.7374     0.7374  0.7374  0.7374  0.027040\n",
       "700     0.7674     0.7674  0.7674  0.7674  0.026581\n",
       "800     0.7457     0.7457  0.7457  0.7457  0.026908\n",
       "900     0.7789     0.7789  0.7789  0.7789  0.026394\n",
       "1000    0.7767     0.7767  0.7767  0.7767  0.026423\n",
       "1100    0.7751     0.7751  0.7751  0.7751  0.026458\n",
       "1200    0.7798     0.7798  0.7798  0.7798  0.026375\n",
       "1300    0.7868     0.7868  0.7868  0.7868  0.026239\n",
       "1400    0.8719     0.8719  0.8719  0.8719  0.024926\n",
       "1500    0.9273     0.9273  0.9273  0.9273  0.024092\n",
       "1600    0.9459     0.9459  0.9459  0.9459  0.023803\n",
       "1700    0.9407     0.9407  0.9407  0.9407  0.023884\n",
       "1800    0.9370     0.9370  0.9370  0.9370  0.023937\n",
       "1900    0.9541     0.9541  0.9541  0.9541  0.023672\n",
       "2000    0.9361     0.9361  0.9361  0.9361  0.023932"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1032</td>\n",
       "      <td>0.1032</td>\n",
       "      <td>0.1032</td>\n",
       "      <td>0.1032</td>\n",
       "      <td>0.036150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.2830</td>\n",
       "      <td>0.2830</td>\n",
       "      <td>0.2830</td>\n",
       "      <td>0.2830</td>\n",
       "      <td>0.036094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.5273</td>\n",
       "      <td>0.5273</td>\n",
       "      <td>0.5273</td>\n",
       "      <td>0.5273</td>\n",
       "      <td>0.030303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.5687</td>\n",
       "      <td>0.5687</td>\n",
       "      <td>0.5687</td>\n",
       "      <td>0.5687</td>\n",
       "      <td>0.029614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0.7060</td>\n",
       "      <td>0.7060</td>\n",
       "      <td>0.7060</td>\n",
       "      <td>0.7060</td>\n",
       "      <td>0.027585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.7497</td>\n",
       "      <td>0.7497</td>\n",
       "      <td>0.7497</td>\n",
       "      <td>0.7497</td>\n",
       "      <td>0.026857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.7374</td>\n",
       "      <td>0.7374</td>\n",
       "      <td>0.7374</td>\n",
       "      <td>0.7374</td>\n",
       "      <td>0.027040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>0.7674</td>\n",
       "      <td>0.7674</td>\n",
       "      <td>0.7674</td>\n",
       "      <td>0.7674</td>\n",
       "      <td>0.026581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>0.7457</td>\n",
       "      <td>0.7457</td>\n",
       "      <td>0.7457</td>\n",
       "      <td>0.7457</td>\n",
       "      <td>0.026908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>0.7789</td>\n",
       "      <td>0.7789</td>\n",
       "      <td>0.7789</td>\n",
       "      <td>0.7789</td>\n",
       "      <td>0.026394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.7767</td>\n",
       "      <td>0.7767</td>\n",
       "      <td>0.7767</td>\n",
       "      <td>0.7767</td>\n",
       "      <td>0.026423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>0.7751</td>\n",
       "      <td>0.7751</td>\n",
       "      <td>0.7751</td>\n",
       "      <td>0.7751</td>\n",
       "      <td>0.026458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>0.7798</td>\n",
       "      <td>0.7798</td>\n",
       "      <td>0.7798</td>\n",
       "      <td>0.7798</td>\n",
       "      <td>0.026375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>0.7868</td>\n",
       "      <td>0.7868</td>\n",
       "      <td>0.7868</td>\n",
       "      <td>0.7868</td>\n",
       "      <td>0.026239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>0.8719</td>\n",
       "      <td>0.8719</td>\n",
       "      <td>0.8719</td>\n",
       "      <td>0.8719</td>\n",
       "      <td>0.024926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>0.9273</td>\n",
       "      <td>0.9273</td>\n",
       "      <td>0.9273</td>\n",
       "      <td>0.9273</td>\n",
       "      <td>0.024092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.023803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>0.9407</td>\n",
       "      <td>0.9407</td>\n",
       "      <td>0.9407</td>\n",
       "      <td>0.9407</td>\n",
       "      <td>0.023884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>0.9370</td>\n",
       "      <td>0.9370</td>\n",
       "      <td>0.9370</td>\n",
       "      <td>0.9370</td>\n",
       "      <td>0.023937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.023672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>0.9361</td>\n",
       "      <td>0.9361</td>\n",
       "      <td>0.9361</td>\n",
       "      <td>0.9361</td>\n",
       "      <td>0.023932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 95
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
